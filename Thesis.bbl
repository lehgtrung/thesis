% Generated by IEEEtranS.bst, version: 1.12 (2007/01/11)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtranS.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{bengio1994}
Y.~Bengio, P.~Simard, and P.~Frasconi, ``Learning long-term dependencies with
  gradient descent is difficult,'' \emph{IEEE Transactions on Neural Networks},
  vol.~5, no.~2, pp. 157--166, Mar 1994.

\bibitem{bengio2013}
Y.~Bengio, N.~Boulanger{-}Lewandowski, and R.~Pascanu, ``Advances in optimizing
  recurrent networks,'' \emph{CoRR}, vol. abs/1212.0901, 2012.

\bibitem{bengioLM2003}
Y.~Bengio, R.~Ducharme, P.~Vincent, and C.~Janvin, ``A neural probabilistic
  language model,'' \emph{J. Mach. Learn. Res.}, vol.~3, pp. 1137--1155, Mar.
  2003.

\bibitem{wordembeddingBengio2003}
------, ``A neural probabilistic language model,'' \emph{J. Mach. Learn. Res.},
  vol.~3, pp. 1137--1155, Mar. 2003.

\bibitem{cho}
K.~Cho, B.~van Merrienboer, C.~Gulcehre, D.~Bahdanau, F.~Bougares, H.~Schwenk,
  and Y.~Bengio, ``Learning phrase representations using rnn encoder--decoder
  for statistical machine translation,'' in \emph{Proceedings of the 2014
  Conference on Empirical Methods in Natural Language Processing
  (EMNLP)}.\hskip 1em plus 0.5em minus 0.4em\relax Doha, Qatar: Association for
  Computational Linguistics, October 2014, pp. 1724--1734.

\bibitem{wordembeddingCollobert2008}
R.~Collobert and J.~Weston, ``A unified architecture for natural language
  processing: Deep neural networks with multitask learning,'' in
  \emph{Proceedings of the 25th International Conference on Machine Learning},
  ser. ICML '08.\hskip 1em plus 0.5em minus 0.4em\relax New York, NY, USA: ACM,
  2008, pp. 160--167.

\bibitem{attentionhistory2011}
\BIBentryALTinterwordspacing
M.~Denil, L.~Bazzani, H.~Larochelle, and N.~de~Freitas, ``Learning where to
  attend with deep architectures for image tracking,'' \emph{CoRR}, vol.
  abs/1109.3737, 2011. [Online]. Available:
  \url{http://arxiv.org/abs/1109.3737}
\BIBentrySTDinterwordspacing

\bibitem{VocabReference1ReadingTeacher}
J.~E.~K. Edward B.~Fry. (2006) The reading teacher's book of lists, 5th
  edition.

\bibitem{elman1990}
J.~L. Elman, ``Finding structure in time,'' \emph{Cognitive Science}, vol.~14,
  no.~2, pp. 179 -- 211, 1990.

\bibitem{gers2000}
F.~A. Gers, J.~Schmidhuber, and F.~Cummins, ``Learning to forget: continual
  prediction with lstm,'' in \emph{1999 Ninth International Conference on
  Artificial Neural Networks ICANN 99. (Conf. Publ. No. 470)}, vol.~2, 1999,
  pp. 850--855 vol.2.

\bibitem{goodman2001}
J.~Goodman, ``A bit of progress in language modeling,'' \emph{CoRR}, vol.
  cs.CL/0108005, 2001.

\bibitem{StanfordNMT}
\BIBentryALTinterwordspacing
T.~S. N. L.~P. Group. (2015) Neural machine translation. [Online]. Available:
  \url{https://nlp.stanford.edu/projects/nmt/}
\BIBentrySTDinterwordspacing

\bibitem{hochreiter1997}
S.~Hochreiter and J.~Schmidhuber, ``Long short-term memory,'' \emph{Neural
  Comput.}, vol.~9, no.~8, pp. 1735--1780, Nov. 1997.

\bibitem{hutchins}
W.~J. Hutchins, ``Machine translation: A concise history,'' 2007.

\bibitem{jaeger2007}
H.~Jaeger, M.~Lukoševičius, D.~Popovici, and U.~Siewert, ``Optimization and
  applications of echo state networks with leaky- integrator neurons,''
  \emph{Neural Networks}, vol.~20, no.~3, pp. 335 -- 352, 2007, echo State
  Networks and Liquid State Machines.

\bibitem{JeanUnkRepl}
\BIBentryALTinterwordspacing
S.~Jean, K.~Cho, R.~Memisevic, and Y.~Bengio, ``On using very large target
  vocabulary for neural machine translation,'' \emph{CoRR}, vol. abs/1412.2007,
  2014. [Online]. Available: \url{http://arxiv.org/abs/1412.2007}
\BIBentrySTDinterwordspacing

\bibitem{VocabReference2LexicalFacts}
Johnson. (2013) Vocabulary size lexical facts.

\bibitem{jurafsky2000}
D.~Jurafsky and J.~H. Martin, \emph{Speech and Language Processing: An
  Introduction to Natural Language Processing, Computational Linguistics, and
  Speech Recognition}, 1st~ed.\hskip 1em plus 0.5em minus 0.4em\relax Upper
  Saddle River, NJ, USA: Prentice Hall PTR, 2000.

\bibitem{kalchbrennerBlunsom}
N.~Kalchbrenner and P.~Blunsom, ``Recurrent continuous translation models,'' in
  \emph{Proceedings of the 2013 Conference on Empirical Methods in Natural
  Language Processing}.\hskip 1em plus 0.5em minus 0.4em\relax Seattle,
  Washington, USA: Association for Computational Linguistics, October 2013, pp.
  1700--1709.

\bibitem{smtKoehn2003}
\BIBentryALTinterwordspacing
P.~Koehn, F.~J. Och, and D.~Marcu, ``Statistical phrase-based translation,'' in
  \emph{Proceedings of the 2003 Conference of the North American Chapter of the
  Association for Computational Linguistics on Human Language Technology -
  Volume 1}, ser. NAACL '03.\hskip 1em plus 0.5em minus 0.4em\relax
  Stroudsburg, PA, USA: Association for Computational Linguistics, 2003, pp.
  48--54. [Online]. Available: \url{https://doi.org/10.3115/1073445.1073462}
\BIBentrySTDinterwordspacing

\bibitem{attentionhistory2010}
\BIBentryALTinterwordspacing
H.~Larochelle and G.~E. Hinton, ``Learning to combine foveal glimpses with a
  third-order boltzmann machine,'' in \emph{Advances in Neural Information
  Processing Systems 23}, J.~D. Lafferty, C.~K.~I. Williams, J.~Shawe-Taylor,
  R.~S. Zemel, and A.~Culotta, Eds.\hskip 1em plus 0.5em minus 0.4em\relax
  Curran Associates, Inc., 2010, pp. 1243--1251. [Online]. Available:
  \url{http://papers.nips.cc/paper/4089-learning-to-combine-foveal-glimpses-with-a-third-order-boltzmann-machine.pdf}
\BIBentrySTDinterwordspacing

\bibitem{attentionThangLuong2015}
\BIBentryALTinterwordspacing
M.~Luong, H.~Pham, and C.~D. Manning, ``Effective approaches to attention-based
  neural machine translation,'' \emph{CoRR}, vol. abs/1508.04025, 2015.
  [Online]. Available: \url{http://arxiv.org/abs/1508.04025}
\BIBentrySTDinterwordspacing

\bibitem{massetal2012}
A.~Maas, Q.~V. Le, T.~M. O’Neil, O.~Vinyals, P.~Nguyen, and A.~Y. Ng,
  ``Recurrent neural networks for noise reduction in robust asr,'' in
  \emph{INTERSPEECH}, 2012.

\bibitem{martens2011}
J.~Martens and I.~Sutskever, ``Learning recurrent neural networks with
  hessian-free optimization,'' in \emph{Proceedings of the 28th International
  Conference on International Conference on Machine Learning}, ser.
  ICML'11.\hskip 1em plus 0.5em minus 0.4em\relax USA: Omnipress, 2011, pp.
  1033--1040.

\bibitem{mikolovLM}
T.~Mikolov, M.~Karafiát, L.~Burget, J.~Cernocký, and S.~Khudanpur,
  ``Recurrent neural network based language model.'' in \emph{INTERSPEECH},
  T.~Kobayashi, K.~Hirose, and S.~Nakamura, Eds.\hskip 1em plus 0.5em minus
  0.4em\relax ISCA, 2010, pp. 1045--1048.

\bibitem{word2vec2013}
T.~Mikolov, I.~Sutskever, K.~Chen, G.~Corrado, and J.~Dean, ``Distributed
  representations of words and phrases and their compositionality,'' in
  \emph{Proceedings of the 26th International Conference on Neural Information
  Processing Systems - Volume 2}, ser. NIPS'13.\hskip 1em plus 0.5em minus
  0.4em\relax USA: Curran Associates Inc., 2013, pp. 3111--3119.

\bibitem{BLEUpaper}
\BIBentryALTinterwordspacing
K.~Papineni, S.~Roukos, T.~Ward, and W.-J. Zhu, ``Bleu: A method for automatic
  evaluation of machine translation,'' in \emph{Proceedings of the 40th Annual
  Meeting on Association for Computational Linguistics}, ser. ACL '02.\hskip
  1em plus 0.5em minus 0.4em\relax Stroudsburg, PA, USA: Association for
  Computational Linguistics, 2002, pp. 311--318. [Online]. Available:
  \url{https://doi.org/10.3115/1073083.1073135}
\BIBentrySTDinterwordspacing

\bibitem{pascanu2011}
R.~Pascanu, T.~Mikolov, and Y.~Bengio, ``On the difficulty of training
  recurrent neural networks,'' \emph{CoRR}, vol. abs/1211.5063, 2012.

\bibitem{pytorchworkshop}
A.~Paszke, S.~Gross, S.~Chintala, G.~Chanan, E.~Yang, Z.~DeVito, Z.~Lin,
  A.~Desmaison, L.~Antiga, and A.~Lerer, ``Automatic differentiation in
  pytorch,'' 2017.

\bibitem{glove2014}
J.~Pennington, R.~Socher, and C.~D. Manning, ``Glove: Global vectors for word
  representation,'' in \emph{Empirical Methods in Natural Language Processing
  (EMNLP)}, 2014, pp. 1532--1543.

\bibitem{distributedrepHinton}
D.~E. Rumelhart, G.~E. Hinton, and R.~J. Williams, ``Neurocomputing:
  Foundations of research,'' J.~A. Anderson and E.~Rosenfeld, Eds.\hskip 1em
  plus 0.5em minus 0.4em\relax Cambridge, MA, USA: MIT Press, 1988, ch.
  Learning Representations by Back-propagating Errors, pp. 696--699.

\bibitem{Seq2Seq2014}
\BIBentryALTinterwordspacing
I.~Sutskever, O.~Vinyals, and Q.~V. Le, ``Sequence to sequence learning with
  neural networks,'' \emph{CoRR}, vol. abs/1409.3215, 2014. [Online].
  Available: \url{http://arxiv.org/abs/1409.3215}
\BIBentrySTDinterwordspacing

\bibitem{werbos1990}
P.~J. Werbos, ``Backpropagation through time: what it does and how to do it,''
  \emph{Proceedings of the IEEE}, vol.~78, no.~10, pp. 1550--1560, Oct 1990.

\bibitem{showattendandtellXu2015}
\BIBentryALTinterwordspacing
K.~Xu, J.~Ba, R.~Kiros, K.~Cho, A.~C. Courville, R.~Salakhutdinov, R.~S. Zemel,
  and Y.~Bengio, ``Show, attend and tell: Neural image caption generation with
  visual attention,'' \emph{CoRR}, vol. abs/1502.03044, 2015. [Online].
  Available: \url{http://arxiv.org/abs/1502.03044}
\BIBentrySTDinterwordspacing

\end{thebibliography}
